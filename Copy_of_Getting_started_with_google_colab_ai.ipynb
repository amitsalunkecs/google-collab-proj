{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amitsalunkecs/google-collab-proj/blob/main/Copy_of_Getting_started_with_google_colab_ai.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "wdj9RMfoGPC2"
      },
      "cell_type": "markdown",
      "source": [
        "Colab is making it easier than ever to integrate powerful Generative AI capabilities into your projects. We are launching public preview for a simple and intuitive Python library (google.colab.ai) to access state-of-the-art language models directly within Colab environments. All users have free access to most popular LLMs, while paid users have access to a wider selection of models. This means users can spend less time on configuration and set up and more time bringing their ideas to life. With just a few lines of code, you can now perform a variety of tasks:\n",
        "- Generate text\n",
        "- Translate languages\n",
        "- Write creative content\n",
        "- Categorize text\n",
        "\n",
        "Happy Coding!\n",
        "\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/googlecolab/colabtools/blob/main/notebooks/Getting_started_with_google_colab_ai.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "Ucchuu5vV3Jp",
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "# @title List available models\n",
        "from google.colab import ai\n",
        "\n",
        "ai.list_models()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#Defining the Search Tool\n",
        "!pip install -U langchain_openai\n",
        "!pip install -U langchain_google_genai\n",
        "!pip install -U langchain_community\n",
        "!pip install -U langchain-google-community\n",
        "\n",
        "# Colab's userdata module\n",
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "os.environ['GEMINI_API_KEY'] = userdata.get('GEMINI_API_KEY')\n",
        "os.environ['GOOGLE_API_KEY'] = userdata.get('GOOGLE_API_KEY')\n",
        "os.environ['GOOGLE_CSE_ID'] = userdata.get('GOOGLE_CSE_ID')\n",
        "os.environ['SERP_API_KEY'] = userdata.get('SERPER_KEY')\n",
        "\n",
        "#Defining the Search Tool\n",
        "from langchain_core.tools import Tool\n",
        "from langchain_google_community import GoogleSearchAPIWrapper\n",
        "\n",
        "search = GoogleSearchAPIWrapper()\n",
        "\n",
        "def top5_results(query):\n",
        "    return search.results(query, 5)\n",
        "\n",
        "search_tool = Tool(\n",
        "    name=\"Google Search\",\n",
        "    description=\"Searches Google for recent results.\",\n",
        "    func=top5_results,\n",
        ")\n",
        "\n",
        "#Chaining the Model with a Prompt\n",
        "\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "model = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\")\n",
        "model.bind_tools(tools=[search_tool])\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    template=\"Please Search this {topic} and give me a precise accurate result.\",\n",
        "    input_variables=[\"topic\"]\n",
        ")\n",
        "\n",
        "chain = prompt | model | StrOutputParser()\n",
        "\n",
        "result = chain.invoke({'topic': 'When Bangladesh was born? with information link'})\n",
        "print(result)\n",
        "\n",
        "\n",
        "#Structured Output with Pydantic\n",
        "\n",
        "from pydantic import BaseModel, Field\n",
        "from typing import Optional\n",
        "\n",
        "class WebResult(BaseModel):\n",
        "    web_result: str = Field(..., description=\"The result of the web page.\")\n",
        "    link: Optional[str] = Field(default=None, description=\"The link to the web page.\")\n",
        "\n",
        "structured_model_pydantic = model.with_structured_output(WebResult)\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    template=\"Please make a report on {topic} \",\n",
        "    input_variables=[\"topic\"]\n",
        ")\n",
        "\n",
        "chain = prompt | structured_model_pydantic\n",
        "\n",
        "result = chain.invoke({'topic': 'why coldwar did happen?'})\n",
        "print(result)\n"
      ],
      "metadata": {
        "id": "K3JDtxPvYPgy"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}